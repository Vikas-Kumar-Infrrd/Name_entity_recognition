{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "data = pd.read_csv(\"ner_dataset.csv\", encoding=\"latin1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.fillna(method=\"ffill\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sentence #</th>\n",
       "      <th>Word</th>\n",
       "      <th>POS</th>\n",
       "      <th>Tag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1048565</th>\n",
       "      <td>Sentence: 47958</td>\n",
       "      <td>impact</td>\n",
       "      <td>NN</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1048566</th>\n",
       "      <td>Sentence: 47958</td>\n",
       "      <td>.</td>\n",
       "      <td>.</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1048567</th>\n",
       "      <td>Sentence: 47959</td>\n",
       "      <td>Indian</td>\n",
       "      <td>JJ</td>\n",
       "      <td>B-gpe</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1048568</th>\n",
       "      <td>Sentence: 47959</td>\n",
       "      <td>forces</td>\n",
       "      <td>NNS</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1048569</th>\n",
       "      <td>Sentence: 47959</td>\n",
       "      <td>said</td>\n",
       "      <td>VBD</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1048570</th>\n",
       "      <td>Sentence: 47959</td>\n",
       "      <td>they</td>\n",
       "      <td>PRP</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1048571</th>\n",
       "      <td>Sentence: 47959</td>\n",
       "      <td>responded</td>\n",
       "      <td>VBD</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1048572</th>\n",
       "      <td>Sentence: 47959</td>\n",
       "      <td>to</td>\n",
       "      <td>TO</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1048573</th>\n",
       "      <td>Sentence: 47959</td>\n",
       "      <td>the</td>\n",
       "      <td>DT</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1048574</th>\n",
       "      <td>Sentence: 47959</td>\n",
       "      <td>attack</td>\n",
       "      <td>NN</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              Sentence #       Word  POS    Tag\n",
       "1048565  Sentence: 47958     impact   NN      O\n",
       "1048566  Sentence: 47958          .    .      O\n",
       "1048567  Sentence: 47959     Indian   JJ  B-gpe\n",
       "1048568  Sentence: 47959     forces  NNS      O\n",
       "1048569  Sentence: 47959       said  VBD      O\n",
       "1048570  Sentence: 47959       they  PRP      O\n",
       "1048571  Sentence: 47959  responded  VBD      O\n",
       "1048572  Sentence: 47959         to   TO      O\n",
       "1048573  Sentence: 47959        the   DT      O\n",
       "1048574  Sentence: 47959     attack   NN      O"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.tail(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "words = list(set(data[\"Word\"].values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "35178"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_words = len(words); n_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SentenceGetter(object):\n",
    "    \n",
    "    def __init__(self, data):\n",
    "        self.n_sent = 1\n",
    "        self.data = data\n",
    "        self.empty = False\n",
    "        agg_func = lambda s: [(w, p, t) for w, p, t in zip(s[\"Word\"].values.tolist(),\n",
    "                                                           s[\"POS\"].values.tolist(),\n",
    "                                                           s[\"Tag\"].values.tolist())]\n",
    "        self.grouped = self.data.groupby(\"Sentence #\").apply(agg_func)\n",
    "        self.sentences = [s for s in self.grouped]\n",
    "    \n",
    "    def get_next(self):\n",
    "        try:\n",
    "            s = self.grouped[\"Sentence: {}\".format(self.n_sent)]\n",
    "            self.n_sent += 1\n",
    "            return s\n",
    "        except:\n",
    "            return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "getter = SentenceGetter(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "sent = getter.get_next()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('Thousands', 'NNS', 'O'), ('of', 'IN', 'O'), ('demonstrators', 'NNS', 'O'), ('have', 'VBP', 'O'), ('marched', 'VBN', 'O'), ('through', 'IN', 'O'), ('London', 'NNP', 'B-geo'), ('to', 'TO', 'O'), ('protest', 'VB', 'O'), ('the', 'DT', 'O'), ('war', 'NN', 'O'), ('in', 'IN', 'O'), ('Iraq', 'NNP', 'B-geo'), ('and', 'CC', 'O'), ('demand', 'VB', 'O'), ('the', 'DT', 'O'), ('withdrawal', 'NN', 'O'), ('of', 'IN', 'O'), ('British', 'JJ', 'B-gpe'), ('troops', 'NNS', 'O'), ('from', 'IN', 'O'), ('that', 'DT', 'O'), ('country', 'NN', 'O'), ('.', '.', 'O')]\n"
     ]
    }
   ],
   "source": [
    "print(sent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences = getter.sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def word2features(sent, i):\n",
    "    word = sent[i][0]\n",
    "    postag = sent[i][1]\n",
    "\n",
    "    features = {\n",
    "        'bias': 1.0,\n",
    "        'word.lower()': word.lower(),\n",
    "        'word[-3:]': word[-3:],\n",
    "        'word[-2:]': word[-2:],\n",
    "        'word.isupper()': word.isupper(),\n",
    "        'word.istitle()': word.istitle(),\n",
    "        'word.isdigit()': word.isdigit(),\n",
    "        'postag': postag,\n",
    "        'postag[:2]': postag[:2],\n",
    "    }\n",
    "    if i > 0:\n",
    "        word1 = sent[i-1][0]\n",
    "        postag1 = sent[i-1][1]\n",
    "        features.update({\n",
    "            '-1:word.lower()': word1.lower(),\n",
    "            '-1:word.istitle()': word1.istitle(),\n",
    "            '-1:word.isupper()': word1.isupper(),\n",
    "            '-1:postag': postag1,\n",
    "            '-1:postag[:2]': postag1[:2],\n",
    "        })\n",
    "    else:\n",
    "        features['BOS'] = True\n",
    "\n",
    "    if i < len(sent)-1:\n",
    "        word1 = sent[i+1][0]\n",
    "        postag1 = sent[i+1][1]\n",
    "        features.update({\n",
    "            '+1:word.lower()': word1.lower(),\n",
    "            '+1:word.istitle()': word1.istitle(),\n",
    "            '+1:word.isupper()': word1.isupper(),\n",
    "            '+1:postag': postag1,\n",
    "            '+1:postag[:2]': postag1[:2],\n",
    "        })\n",
    "    else:\n",
    "        features['EOS'] = True\n",
    "\n",
    "    return features\n",
    "\n",
    "\n",
    "def sent2features(sent):\n",
    "    return [word2features(sent, i) for i in range(len(sent))]\n",
    "\n",
    "def sent2labels(sent):\n",
    "    return [label for token, postag, label in sent]\n",
    "\n",
    "def sent2tokens(sent):\n",
    "    return [token for token, postag, label in sent]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = [sent2features(s) for s in sentences]\n",
    "y = [sent2labels(s) for s in sentences]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn_crfsuite import CRF\n",
    "\n",
    "crf = CRF(algorithm='lbfgs',\n",
    "          c1=0.1,\n",
    "          c2=0.1,\n",
    "          max_iterations=100,\n",
    "          all_possible_transitions=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install sklearn_crfsuite"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user/anaconda3/lib/python3.6/site-packages/sklearn/cross_validation.py:41: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.cross_validation import cross_val_predict\n",
    "from sklearn_crfsuite.metrics import flat_classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = cross_val_predict(estimator=crf, X=X, y=y, cv=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "      B-art       0.37      0.11      0.17       402\n",
      "      B-eve       0.52      0.35      0.42       308\n",
      "      B-geo       0.85      0.90      0.88     37644\n",
      "      B-gpe       0.97      0.94      0.95     15870\n",
      "      B-nat       0.66      0.37      0.47       201\n",
      "      B-org       0.78      0.72      0.75     20143\n",
      "      B-per       0.84      0.81      0.82     16990\n",
      "      B-tim       0.93      0.88      0.90     20333\n",
      "      I-art       0.11      0.03      0.04       297\n",
      "      I-eve       0.34      0.21      0.26       253\n",
      "      I-geo       0.82      0.79      0.80      7414\n",
      "      I-gpe       0.92      0.55      0.69       198\n",
      "      I-nat       0.61      0.27      0.38        51\n",
      "      I-org       0.81      0.79      0.80     16784\n",
      "      I-per       0.84      0.89      0.87     17251\n",
      "      I-tim       0.83      0.76      0.80      6528\n",
      "          O       0.99      0.99      0.99    887908\n",
      "\n",
      "avg / total       0.97      0.97      0.97   1048575\n",
      "\n"
     ]
    }
   ],
   "source": [
    "report = flat_classification_report(y_pred=pred, y_true=y)\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "list"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[{'bias': 1.0,\n",
       "   'word.lower()': 'thousands',\n",
       "   'word[-3:]': 'nds',\n",
       "   'word[-2:]': 'ds',\n",
       "   'word.isupper()': False,\n",
       "   'word.istitle()': True,\n",
       "   'word.isdigit()': False,\n",
       "   'postag': 'NNS',\n",
       "   'postag[:2]': 'NN',\n",
       "   'BOS': True,\n",
       "   '+1:word.lower()': 'of',\n",
       "   '+1:word.istitle()': False,\n",
       "   '+1:word.isupper()': False,\n",
       "   '+1:postag': 'IN',\n",
       "   '+1:postag[:2]': 'IN'},\n",
       "  {'bias': 1.0,\n",
       "   'word.lower()': 'of',\n",
       "   'word[-3:]': 'of',\n",
       "   'word[-2:]': 'of',\n",
       "   'word.isupper()': False,\n",
       "   'word.istitle()': False,\n",
       "   'word.isdigit()': False,\n",
       "   'postag': 'IN',\n",
       "   'postag[:2]': 'IN',\n",
       "   '-1:word.lower()': 'thousands',\n",
       "   '-1:word.istitle()': True,\n",
       "   '-1:word.isupper()': False,\n",
       "   '-1:postag': 'NNS',\n",
       "   '-1:postag[:2]': 'NN',\n",
       "   '+1:word.lower()': 'demonstrators',\n",
       "   '+1:word.istitle()': False,\n",
       "   '+1:word.isupper()': False,\n",
       "   '+1:postag': 'NNS',\n",
       "   '+1:postag[:2]': 'NN'},\n",
       "  {'bias': 1.0,\n",
       "   'word.lower()': 'demonstrators',\n",
       "   'word[-3:]': 'ors',\n",
       "   'word[-2:]': 'rs',\n",
       "   'word.isupper()': False,\n",
       "   'word.istitle()': False,\n",
       "   'word.isdigit()': False,\n",
       "   'postag': 'NNS',\n",
       "   'postag[:2]': 'NN',\n",
       "   '-1:word.lower()': 'of',\n",
       "   '-1:word.istitle()': False,\n",
       "   '-1:word.isupper()': False,\n",
       "   '-1:postag': 'IN',\n",
       "   '-1:postag[:2]': 'IN',\n",
       "   '+1:word.lower()': 'have',\n",
       "   '+1:word.istitle()': False,\n",
       "   '+1:word.isupper()': False,\n",
       "   '+1:postag': 'VBP',\n",
       "   '+1:postag[:2]': 'VB'},\n",
       "  {'bias': 1.0,\n",
       "   'word.lower()': 'have',\n",
       "   'word[-3:]': 'ave',\n",
       "   'word[-2:]': 've',\n",
       "   'word.isupper()': False,\n",
       "   'word.istitle()': False,\n",
       "   'word.isdigit()': False,\n",
       "   'postag': 'VBP',\n",
       "   'postag[:2]': 'VB',\n",
       "   '-1:word.lower()': 'demonstrators',\n",
       "   '-1:word.istitle()': False,\n",
       "   '-1:word.isupper()': False,\n",
       "   '-1:postag': 'NNS',\n",
       "   '-1:postag[:2]': 'NN',\n",
       "   '+1:word.lower()': 'marched',\n",
       "   '+1:word.istitle()': False,\n",
       "   '+1:word.isupper()': False,\n",
       "   '+1:postag': 'VBN',\n",
       "   '+1:postag[:2]': 'VB'},\n",
       "  {'bias': 1.0,\n",
       "   'word.lower()': 'marched',\n",
       "   'word[-3:]': 'hed',\n",
       "   'word[-2:]': 'ed',\n",
       "   'word.isupper()': False,\n",
       "   'word.istitle()': False,\n",
       "   'word.isdigit()': False,\n",
       "   'postag': 'VBN',\n",
       "   'postag[:2]': 'VB',\n",
       "   '-1:word.lower()': 'have',\n",
       "   '-1:word.istitle()': False,\n",
       "   '-1:word.isupper()': False,\n",
       "   '-1:postag': 'VBP',\n",
       "   '-1:postag[:2]': 'VB',\n",
       "   '+1:word.lower()': 'through',\n",
       "   '+1:word.istitle()': False,\n",
       "   '+1:word.isupper()': False,\n",
       "   '+1:postag': 'IN',\n",
       "   '+1:postag[:2]': 'IN'},\n",
       "  {'bias': 1.0,\n",
       "   'word.lower()': 'through',\n",
       "   'word[-3:]': 'ugh',\n",
       "   'word[-2:]': 'gh',\n",
       "   'word.isupper()': False,\n",
       "   'word.istitle()': False,\n",
       "   'word.isdigit()': False,\n",
       "   'postag': 'IN',\n",
       "   'postag[:2]': 'IN',\n",
       "   '-1:word.lower()': 'marched',\n",
       "   '-1:word.istitle()': False,\n",
       "   '-1:word.isupper()': False,\n",
       "   '-1:postag': 'VBN',\n",
       "   '-1:postag[:2]': 'VB',\n",
       "   '+1:word.lower()': 'london',\n",
       "   '+1:word.istitle()': True,\n",
       "   '+1:word.isupper()': False,\n",
       "   '+1:postag': 'NNP',\n",
       "   '+1:postag[:2]': 'NN'},\n",
       "  {'bias': 1.0,\n",
       "   'word.lower()': 'london',\n",
       "   'word[-3:]': 'don',\n",
       "   'word[-2:]': 'on',\n",
       "   'word.isupper()': False,\n",
       "   'word.istitle()': True,\n",
       "   'word.isdigit()': False,\n",
       "   'postag': 'NNP',\n",
       "   'postag[:2]': 'NN',\n",
       "   '-1:word.lower()': 'through',\n",
       "   '-1:word.istitle()': False,\n",
       "   '-1:word.isupper()': False,\n",
       "   '-1:postag': 'IN',\n",
       "   '-1:postag[:2]': 'IN',\n",
       "   '+1:word.lower()': 'to',\n",
       "   '+1:word.istitle()': False,\n",
       "   '+1:word.isupper()': False,\n",
       "   '+1:postag': 'TO',\n",
       "   '+1:postag[:2]': 'TO'},\n",
       "  {'bias': 1.0,\n",
       "   'word.lower()': 'to',\n",
       "   'word[-3:]': 'to',\n",
       "   'word[-2:]': 'to',\n",
       "   'word.isupper()': False,\n",
       "   'word.istitle()': False,\n",
       "   'word.isdigit()': False,\n",
       "   'postag': 'TO',\n",
       "   'postag[:2]': 'TO',\n",
       "   '-1:word.lower()': 'london',\n",
       "   '-1:word.istitle()': True,\n",
       "   '-1:word.isupper()': False,\n",
       "   '-1:postag': 'NNP',\n",
       "   '-1:postag[:2]': 'NN',\n",
       "   '+1:word.lower()': 'protest',\n",
       "   '+1:word.istitle()': False,\n",
       "   '+1:word.isupper()': False,\n",
       "   '+1:postag': 'VB',\n",
       "   '+1:postag[:2]': 'VB'},\n",
       "  {'bias': 1.0,\n",
       "   'word.lower()': 'protest',\n",
       "   'word[-3:]': 'est',\n",
       "   'word[-2:]': 'st',\n",
       "   'word.isupper()': False,\n",
       "   'word.istitle()': False,\n",
       "   'word.isdigit()': False,\n",
       "   'postag': 'VB',\n",
       "   'postag[:2]': 'VB',\n",
       "   '-1:word.lower()': 'to',\n",
       "   '-1:word.istitle()': False,\n",
       "   '-1:word.isupper()': False,\n",
       "   '-1:postag': 'TO',\n",
       "   '-1:postag[:2]': 'TO',\n",
       "   '+1:word.lower()': 'the',\n",
       "   '+1:word.istitle()': False,\n",
       "   '+1:word.isupper()': False,\n",
       "   '+1:postag': 'DT',\n",
       "   '+1:postag[:2]': 'DT'},\n",
       "  {'bias': 1.0,\n",
       "   'word.lower()': 'the',\n",
       "   'word[-3:]': 'the',\n",
       "   'word[-2:]': 'he',\n",
       "   'word.isupper()': False,\n",
       "   'word.istitle()': False,\n",
       "   'word.isdigit()': False,\n",
       "   'postag': 'DT',\n",
       "   'postag[:2]': 'DT',\n",
       "   '-1:word.lower()': 'protest',\n",
       "   '-1:word.istitle()': False,\n",
       "   '-1:word.isupper()': False,\n",
       "   '-1:postag': 'VB',\n",
       "   '-1:postag[:2]': 'VB',\n",
       "   '+1:word.lower()': 'war',\n",
       "   '+1:word.istitle()': False,\n",
       "   '+1:word.isupper()': False,\n",
       "   '+1:postag': 'NN',\n",
       "   '+1:postag[:2]': 'NN'},\n",
       "  {'bias': 1.0,\n",
       "   'word.lower()': 'war',\n",
       "   'word[-3:]': 'war',\n",
       "   'word[-2:]': 'ar',\n",
       "   'word.isupper()': False,\n",
       "   'word.istitle()': False,\n",
       "   'word.isdigit()': False,\n",
       "   'postag': 'NN',\n",
       "   'postag[:2]': 'NN',\n",
       "   '-1:word.lower()': 'the',\n",
       "   '-1:word.istitle()': False,\n",
       "   '-1:word.isupper()': False,\n",
       "   '-1:postag': 'DT',\n",
       "   '-1:postag[:2]': 'DT',\n",
       "   '+1:word.lower()': 'in',\n",
       "   '+1:word.istitle()': False,\n",
       "   '+1:word.isupper()': False,\n",
       "   '+1:postag': 'IN',\n",
       "   '+1:postag[:2]': 'IN'},\n",
       "  {'bias': 1.0,\n",
       "   'word.lower()': 'in',\n",
       "   'word[-3:]': 'in',\n",
       "   'word[-2:]': 'in',\n",
       "   'word.isupper()': False,\n",
       "   'word.istitle()': False,\n",
       "   'word.isdigit()': False,\n",
       "   'postag': 'IN',\n",
       "   'postag[:2]': 'IN',\n",
       "   '-1:word.lower()': 'war',\n",
       "   '-1:word.istitle()': False,\n",
       "   '-1:word.isupper()': False,\n",
       "   '-1:postag': 'NN',\n",
       "   '-1:postag[:2]': 'NN',\n",
       "   '+1:word.lower()': 'iraq',\n",
       "   '+1:word.istitle()': True,\n",
       "   '+1:word.isupper()': False,\n",
       "   '+1:postag': 'NNP',\n",
       "   '+1:postag[:2]': 'NN'},\n",
       "  {'bias': 1.0,\n",
       "   'word.lower()': 'iraq',\n",
       "   'word[-3:]': 'raq',\n",
       "   'word[-2:]': 'aq',\n",
       "   'word.isupper()': False,\n",
       "   'word.istitle()': True,\n",
       "   'word.isdigit()': False,\n",
       "   'postag': 'NNP',\n",
       "   'postag[:2]': 'NN',\n",
       "   '-1:word.lower()': 'in',\n",
       "   '-1:word.istitle()': False,\n",
       "   '-1:word.isupper()': False,\n",
       "   '-1:postag': 'IN',\n",
       "   '-1:postag[:2]': 'IN',\n",
       "   '+1:word.lower()': 'and',\n",
       "   '+1:word.istitle()': False,\n",
       "   '+1:word.isupper()': False,\n",
       "   '+1:postag': 'CC',\n",
       "   '+1:postag[:2]': 'CC'},\n",
       "  {'bias': 1.0,\n",
       "   'word.lower()': 'and',\n",
       "   'word[-3:]': 'and',\n",
       "   'word[-2:]': 'nd',\n",
       "   'word.isupper()': False,\n",
       "   'word.istitle()': False,\n",
       "   'word.isdigit()': False,\n",
       "   'postag': 'CC',\n",
       "   'postag[:2]': 'CC',\n",
       "   '-1:word.lower()': 'iraq',\n",
       "   '-1:word.istitle()': True,\n",
       "   '-1:word.isupper()': False,\n",
       "   '-1:postag': 'NNP',\n",
       "   '-1:postag[:2]': 'NN',\n",
       "   '+1:word.lower()': 'demand',\n",
       "   '+1:word.istitle()': False,\n",
       "   '+1:word.isupper()': False,\n",
       "   '+1:postag': 'VB',\n",
       "   '+1:postag[:2]': 'VB'},\n",
       "  {'bias': 1.0,\n",
       "   'word.lower()': 'demand',\n",
       "   'word[-3:]': 'and',\n",
       "   'word[-2:]': 'nd',\n",
       "   'word.isupper()': False,\n",
       "   'word.istitle()': False,\n",
       "   'word.isdigit()': False,\n",
       "   'postag': 'VB',\n",
       "   'postag[:2]': 'VB',\n",
       "   '-1:word.lower()': 'and',\n",
       "   '-1:word.istitle()': False,\n",
       "   '-1:word.isupper()': False,\n",
       "   '-1:postag': 'CC',\n",
       "   '-1:postag[:2]': 'CC',\n",
       "   '+1:word.lower()': 'the',\n",
       "   '+1:word.istitle()': False,\n",
       "   '+1:word.isupper()': False,\n",
       "   '+1:postag': 'DT',\n",
       "   '+1:postag[:2]': 'DT'},\n",
       "  {'bias': 1.0,\n",
       "   'word.lower()': 'the',\n",
       "   'word[-3:]': 'the',\n",
       "   'word[-2:]': 'he',\n",
       "   'word.isupper()': False,\n",
       "   'word.istitle()': False,\n",
       "   'word.isdigit()': False,\n",
       "   'postag': 'DT',\n",
       "   'postag[:2]': 'DT',\n",
       "   '-1:word.lower()': 'demand',\n",
       "   '-1:word.istitle()': False,\n",
       "   '-1:word.isupper()': False,\n",
       "   '-1:postag': 'VB',\n",
       "   '-1:postag[:2]': 'VB',\n",
       "   '+1:word.lower()': 'withdrawal',\n",
       "   '+1:word.istitle()': False,\n",
       "   '+1:word.isupper()': False,\n",
       "   '+1:postag': 'NN',\n",
       "   '+1:postag[:2]': 'NN'},\n",
       "  {'bias': 1.0,\n",
       "   'word.lower()': 'withdrawal',\n",
       "   'word[-3:]': 'wal',\n",
       "   'word[-2:]': 'al',\n",
       "   'word.isupper()': False,\n",
       "   'word.istitle()': False,\n",
       "   'word.isdigit()': False,\n",
       "   'postag': 'NN',\n",
       "   'postag[:2]': 'NN',\n",
       "   '-1:word.lower()': 'the',\n",
       "   '-1:word.istitle()': False,\n",
       "   '-1:word.isupper()': False,\n",
       "   '-1:postag': 'DT',\n",
       "   '-1:postag[:2]': 'DT',\n",
       "   '+1:word.lower()': 'of',\n",
       "   '+1:word.istitle()': False,\n",
       "   '+1:word.isupper()': False,\n",
       "   '+1:postag': 'IN',\n",
       "   '+1:postag[:2]': 'IN'},\n",
       "  {'bias': 1.0,\n",
       "   'word.lower()': 'of',\n",
       "   'word[-3:]': 'of',\n",
       "   'word[-2:]': 'of',\n",
       "   'word.isupper()': False,\n",
       "   'word.istitle()': False,\n",
       "   'word.isdigit()': False,\n",
       "   'postag': 'IN',\n",
       "   'postag[:2]': 'IN',\n",
       "   '-1:word.lower()': 'withdrawal',\n",
       "   '-1:word.istitle()': False,\n",
       "   '-1:word.isupper()': False,\n",
       "   '-1:postag': 'NN',\n",
       "   '-1:postag[:2]': 'NN',\n",
       "   '+1:word.lower()': 'british',\n",
       "   '+1:word.istitle()': True,\n",
       "   '+1:word.isupper()': False,\n",
       "   '+1:postag': 'JJ',\n",
       "   '+1:postag[:2]': 'JJ'},\n",
       "  {'bias': 1.0,\n",
       "   'word.lower()': 'british',\n",
       "   'word[-3:]': 'ish',\n",
       "   'word[-2:]': 'sh',\n",
       "   'word.isupper()': False,\n",
       "   'word.istitle()': True,\n",
       "   'word.isdigit()': False,\n",
       "   'postag': 'JJ',\n",
       "   'postag[:2]': 'JJ',\n",
       "   '-1:word.lower()': 'of',\n",
       "   '-1:word.istitle()': False,\n",
       "   '-1:word.isupper()': False,\n",
       "   '-1:postag': 'IN',\n",
       "   '-1:postag[:2]': 'IN',\n",
       "   '+1:word.lower()': 'troops',\n",
       "   '+1:word.istitle()': False,\n",
       "   '+1:word.isupper()': False,\n",
       "   '+1:postag': 'NNS',\n",
       "   '+1:postag[:2]': 'NN'},\n",
       "  {'bias': 1.0,\n",
       "   'word.lower()': 'troops',\n",
       "   'word[-3:]': 'ops',\n",
       "   'word[-2:]': 'ps',\n",
       "   'word.isupper()': False,\n",
       "   'word.istitle()': False,\n",
       "   'word.isdigit()': False,\n",
       "   'postag': 'NNS',\n",
       "   'postag[:2]': 'NN',\n",
       "   '-1:word.lower()': 'british',\n",
       "   '-1:word.istitle()': True,\n",
       "   '-1:word.isupper()': False,\n",
       "   '-1:postag': 'JJ',\n",
       "   '-1:postag[:2]': 'JJ',\n",
       "   '+1:word.lower()': 'from',\n",
       "   '+1:word.istitle()': False,\n",
       "   '+1:word.isupper()': False,\n",
       "   '+1:postag': 'IN',\n",
       "   '+1:postag[:2]': 'IN'},\n",
       "  {'bias': 1.0,\n",
       "   'word.lower()': 'from',\n",
       "   'word[-3:]': 'rom',\n",
       "   'word[-2:]': 'om',\n",
       "   'word.isupper()': False,\n",
       "   'word.istitle()': False,\n",
       "   'word.isdigit()': False,\n",
       "   'postag': 'IN',\n",
       "   'postag[:2]': 'IN',\n",
       "   '-1:word.lower()': 'troops',\n",
       "   '-1:word.istitle()': False,\n",
       "   '-1:word.isupper()': False,\n",
       "   '-1:postag': 'NNS',\n",
       "   '-1:postag[:2]': 'NN',\n",
       "   '+1:word.lower()': 'that',\n",
       "   '+1:word.istitle()': False,\n",
       "   '+1:word.isupper()': False,\n",
       "   '+1:postag': 'DT',\n",
       "   '+1:postag[:2]': 'DT'},\n",
       "  {'bias': 1.0,\n",
       "   'word.lower()': 'that',\n",
       "   'word[-3:]': 'hat',\n",
       "   'word[-2:]': 'at',\n",
       "   'word.isupper()': False,\n",
       "   'word.istitle()': False,\n",
       "   'word.isdigit()': False,\n",
       "   'postag': 'DT',\n",
       "   'postag[:2]': 'DT',\n",
       "   '-1:word.lower()': 'from',\n",
       "   '-1:word.istitle()': False,\n",
       "   '-1:word.isupper()': False,\n",
       "   '-1:postag': 'IN',\n",
       "   '-1:postag[:2]': 'IN',\n",
       "   '+1:word.lower()': 'country',\n",
       "   '+1:word.istitle()': False,\n",
       "   '+1:word.isupper()': False,\n",
       "   '+1:postag': 'NN',\n",
       "   '+1:postag[:2]': 'NN'},\n",
       "  {'bias': 1.0,\n",
       "   'word.lower()': 'country',\n",
       "   'word[-3:]': 'try',\n",
       "   'word[-2:]': 'ry',\n",
       "   'word.isupper()': False,\n",
       "   'word.istitle()': False,\n",
       "   'word.isdigit()': False,\n",
       "   'postag': 'NN',\n",
       "   'postag[:2]': 'NN',\n",
       "   '-1:word.lower()': 'that',\n",
       "   '-1:word.istitle()': False,\n",
       "   '-1:word.isupper()': False,\n",
       "   '-1:postag': 'DT',\n",
       "   '-1:postag[:2]': 'DT',\n",
       "   '+1:word.lower()': '.',\n",
       "   '+1:word.istitle()': False,\n",
       "   '+1:word.isupper()': False,\n",
       "   '+1:postag': '.',\n",
       "   '+1:postag[:2]': '.'},\n",
       "  {'bias': 1.0,\n",
       "   'word.lower()': '.',\n",
       "   'word[-3:]': '.',\n",
       "   'word[-2:]': '.',\n",
       "   'word.isupper()': False,\n",
       "   'word.istitle()': False,\n",
       "   'word.isdigit()': False,\n",
       "   'postag': '.',\n",
       "   'postag[:2]': '.',\n",
       "   '-1:word.lower()': 'country',\n",
       "   '-1:word.istitle()': False,\n",
       "   '-1:word.isupper()': False,\n",
       "   '-1:postag': 'NN',\n",
       "   '-1:postag[:2]': 'NN',\n",
       "   'EOS': True}],\n",
       " [{'bias': 1.0,\n",
       "   'word.lower()': 'iranian',\n",
       "   'word[-3:]': 'ian',\n",
       "   'word[-2:]': 'an',\n",
       "   'word.isupper()': False,\n",
       "   'word.istitle()': True,\n",
       "   'word.isdigit()': False,\n",
       "   'postag': 'JJ',\n",
       "   'postag[:2]': 'JJ',\n",
       "   'BOS': True,\n",
       "   '+1:word.lower()': 'officials',\n",
       "   '+1:word.istitle()': False,\n",
       "   '+1:word.isupper()': False,\n",
       "   '+1:postag': 'NNS',\n",
       "   '+1:postag[:2]': 'NN'},\n",
       "  {'bias': 1.0,\n",
       "   'word.lower()': 'officials',\n",
       "   'word[-3:]': 'als',\n",
       "   'word[-2:]': 'ls',\n",
       "   'word.isupper()': False,\n",
       "   'word.istitle()': False,\n",
       "   'word.isdigit()': False,\n",
       "   'postag': 'NNS',\n",
       "   'postag[:2]': 'NN',\n",
       "   '-1:word.lower()': 'iranian',\n",
       "   '-1:word.istitle()': True,\n",
       "   '-1:word.isupper()': False,\n",
       "   '-1:postag': 'JJ',\n",
       "   '-1:postag[:2]': 'JJ',\n",
       "   '+1:word.lower()': 'say',\n",
       "   '+1:word.istitle()': False,\n",
       "   '+1:word.isupper()': False,\n",
       "   '+1:postag': 'VBP',\n",
       "   '+1:postag[:2]': 'VB'},\n",
       "  {'bias': 1.0,\n",
       "   'word.lower()': 'say',\n",
       "   'word[-3:]': 'say',\n",
       "   'word[-2:]': 'ay',\n",
       "   'word.isupper()': False,\n",
       "   'word.istitle()': False,\n",
       "   'word.isdigit()': False,\n",
       "   'postag': 'VBP',\n",
       "   'postag[:2]': 'VB',\n",
       "   '-1:word.lower()': 'officials',\n",
       "   '-1:word.istitle()': False,\n",
       "   '-1:word.isupper()': False,\n",
       "   '-1:postag': 'NNS',\n",
       "   '-1:postag[:2]': 'NN',\n",
       "   '+1:word.lower()': 'they',\n",
       "   '+1:word.istitle()': False,\n",
       "   '+1:word.isupper()': False,\n",
       "   '+1:postag': 'PRP',\n",
       "   '+1:postag[:2]': 'PR'},\n",
       "  {'bias': 1.0,\n",
       "   'word.lower()': 'they',\n",
       "   'word[-3:]': 'hey',\n",
       "   'word[-2:]': 'ey',\n",
       "   'word.isupper()': False,\n",
       "   'word.istitle()': False,\n",
       "   'word.isdigit()': False,\n",
       "   'postag': 'PRP',\n",
       "   'postag[:2]': 'PR',\n",
       "   '-1:word.lower()': 'say',\n",
       "   '-1:word.istitle()': False,\n",
       "   '-1:word.isupper()': False,\n",
       "   '-1:postag': 'VBP',\n",
       "   '-1:postag[:2]': 'VB',\n",
       "   '+1:word.lower()': 'expect',\n",
       "   '+1:word.istitle()': False,\n",
       "   '+1:word.isupper()': False,\n",
       "   '+1:postag': 'VBP',\n",
       "   '+1:postag[:2]': 'VB'},\n",
       "  {'bias': 1.0,\n",
       "   'word.lower()': 'expect',\n",
       "   'word[-3:]': 'ect',\n",
       "   'word[-2:]': 'ct',\n",
       "   'word.isupper()': False,\n",
       "   'word.istitle()': False,\n",
       "   'word.isdigit()': False,\n",
       "   'postag': 'VBP',\n",
       "   'postag[:2]': 'VB',\n",
       "   '-1:word.lower()': 'they',\n",
       "   '-1:word.istitle()': False,\n",
       "   '-1:word.isupper()': False,\n",
       "   '-1:postag': 'PRP',\n",
       "   '-1:postag[:2]': 'PR',\n",
       "   '+1:word.lower()': 'to',\n",
       "   '+1:word.istitle()': False,\n",
       "   '+1:word.isupper()': False,\n",
       "   '+1:postag': 'TO',\n",
       "   '+1:postag[:2]': 'TO'},\n",
       "  {'bias': 1.0,\n",
       "   'word.lower()': 'to',\n",
       "   'word[-3:]': 'to',\n",
       "   'word[-2:]': 'to',\n",
       "   'word.isupper()': False,\n",
       "   'word.istitle()': False,\n",
       "   'word.isdigit()': False,\n",
       "   'postag': 'TO',\n",
       "   'postag[:2]': 'TO',\n",
       "   '-1:word.lower()': 'expect',\n",
       "   '-1:word.istitle()': False,\n",
       "   '-1:word.isupper()': False,\n",
       "   '-1:postag': 'VBP',\n",
       "   '-1:postag[:2]': 'VB',\n",
       "   '+1:word.lower()': 'get',\n",
       "   '+1:word.istitle()': False,\n",
       "   '+1:word.isupper()': False,\n",
       "   '+1:postag': 'VB',\n",
       "   '+1:postag[:2]': 'VB'},\n",
       "  {'bias': 1.0,\n",
       "   'word.lower()': 'get',\n",
       "   'word[-3:]': 'get',\n",
       "   'word[-2:]': 'et',\n",
       "   'word.isupper()': False,\n",
       "   'word.istitle()': False,\n",
       "   'word.isdigit()': False,\n",
       "   'postag': 'VB',\n",
       "   'postag[:2]': 'VB',\n",
       "   '-1:word.lower()': 'to',\n",
       "   '-1:word.istitle()': False,\n",
       "   '-1:word.isupper()': False,\n",
       "   '-1:postag': 'TO',\n",
       "   '-1:postag[:2]': 'TO',\n",
       "   '+1:word.lower()': 'access',\n",
       "   '+1:word.istitle()': False,\n",
       "   '+1:word.isupper()': False,\n",
       "   '+1:postag': 'NN',\n",
       "   '+1:postag[:2]': 'NN'},\n",
       "  {'bias': 1.0,\n",
       "   'word.lower()': 'access',\n",
       "   'word[-3:]': 'ess',\n",
       "   'word[-2:]': 'ss',\n",
       "   'word.isupper()': False,\n",
       "   'word.istitle()': False,\n",
       "   'word.isdigit()': False,\n",
       "   'postag': 'NN',\n",
       "   'postag[:2]': 'NN',\n",
       "   '-1:word.lower()': 'get',\n",
       "   '-1:word.istitle()': False,\n",
       "   '-1:word.isupper()': False,\n",
       "   '-1:postag': 'VB',\n",
       "   '-1:postag[:2]': 'VB',\n",
       "   '+1:word.lower()': 'to',\n",
       "   '+1:word.istitle()': False,\n",
       "   '+1:word.isupper()': False,\n",
       "   '+1:postag': 'TO',\n",
       "   '+1:postag[:2]': 'TO'},\n",
       "  {'bias': 1.0,\n",
       "   'word.lower()': 'to',\n",
       "   'word[-3:]': 'to',\n",
       "   'word[-2:]': 'to',\n",
       "   'word.isupper()': False,\n",
       "   'word.istitle()': False,\n",
       "   'word.isdigit()': False,\n",
       "   'postag': 'TO',\n",
       "   'postag[:2]': 'TO',\n",
       "   '-1:word.lower()': 'access',\n",
       "   '-1:word.istitle()': False,\n",
       "   '-1:word.isupper()': False,\n",
       "   '-1:postag': 'NN',\n",
       "   '-1:postag[:2]': 'NN',\n",
       "   '+1:word.lower()': 'sealed',\n",
       "   '+1:word.istitle()': False,\n",
       "   '+1:word.isupper()': False,\n",
       "   '+1:postag': 'JJ',\n",
       "   '+1:postag[:2]': 'JJ'},\n",
       "  {'bias': 1.0,\n",
       "   'word.lower()': 'sealed',\n",
       "   'word[-3:]': 'led',\n",
       "   'word[-2:]': 'ed',\n",
       "   'word.isupper()': False,\n",
       "   'word.istitle()': False,\n",
       "   'word.isdigit()': False,\n",
       "   'postag': 'JJ',\n",
       "   'postag[:2]': 'JJ',\n",
       "   '-1:word.lower()': 'to',\n",
       "   '-1:word.istitle()': False,\n",
       "   '-1:word.isupper()': False,\n",
       "   '-1:postag': 'TO',\n",
       "   '-1:postag[:2]': 'TO',\n",
       "   '+1:word.lower()': 'sensitive',\n",
       "   '+1:word.istitle()': False,\n",
       "   '+1:word.isupper()': False,\n",
       "   '+1:postag': 'JJ',\n",
       "   '+1:postag[:2]': 'JJ'},\n",
       "  {'bias': 1.0,\n",
       "   'word.lower()': 'sensitive',\n",
       "   'word[-3:]': 'ive',\n",
       "   'word[-2:]': 've',\n",
       "   'word.isupper()': False,\n",
       "   'word.istitle()': False,\n",
       "   'word.isdigit()': False,\n",
       "   'postag': 'JJ',\n",
       "   'postag[:2]': 'JJ',\n",
       "   '-1:word.lower()': 'sealed',\n",
       "   '-1:word.istitle()': False,\n",
       "   '-1:word.isupper()': False,\n",
       "   '-1:postag': 'JJ',\n",
       "   '-1:postag[:2]': 'JJ',\n",
       "   '+1:word.lower()': 'parts',\n",
       "   '+1:word.istitle()': False,\n",
       "   '+1:word.isupper()': False,\n",
       "   '+1:postag': 'NNS',\n",
       "   '+1:postag[:2]': 'NN'},\n",
       "  {'bias': 1.0,\n",
       "   'word.lower()': 'parts',\n",
       "   'word[-3:]': 'rts',\n",
       "   'word[-2:]': 'ts',\n",
       "   'word.isupper()': False,\n",
       "   'word.istitle()': False,\n",
       "   'word.isdigit()': False,\n",
       "   'postag': 'NNS',\n",
       "   'postag[:2]': 'NN',\n",
       "   '-1:word.lower()': 'sensitive',\n",
       "   '-1:word.istitle()': False,\n",
       "   '-1:word.isupper()': False,\n",
       "   '-1:postag': 'JJ',\n",
       "   '-1:postag[:2]': 'JJ',\n",
       "   '+1:word.lower()': 'of',\n",
       "   '+1:word.istitle()': False,\n",
       "   '+1:word.isupper()': False,\n",
       "   '+1:postag': 'IN',\n",
       "   '+1:postag[:2]': 'IN'},\n",
       "  {'bias': 1.0,\n",
       "   'word.lower()': 'of',\n",
       "   'word[-3:]': 'of',\n",
       "   'word[-2:]': 'of',\n",
       "   'word.isupper()': False,\n",
       "   'word.istitle()': False,\n",
       "   'word.isdigit()': False,\n",
       "   'postag': 'IN',\n",
       "   'postag[:2]': 'IN',\n",
       "   '-1:word.lower()': 'parts',\n",
       "   '-1:word.istitle()': False,\n",
       "   '-1:word.isupper()': False,\n",
       "   '-1:postag': 'NNS',\n",
       "   '-1:postag[:2]': 'NN',\n",
       "   '+1:word.lower()': 'the',\n",
       "   '+1:word.istitle()': False,\n",
       "   '+1:word.isupper()': False,\n",
       "   '+1:postag': 'DT',\n",
       "   '+1:postag[:2]': 'DT'},\n",
       "  {'bias': 1.0,\n",
       "   'word.lower()': 'the',\n",
       "   'word[-3:]': 'the',\n",
       "   'word[-2:]': 'he',\n",
       "   'word.isupper()': False,\n",
       "   'word.istitle()': False,\n",
       "   'word.isdigit()': False,\n",
       "   'postag': 'DT',\n",
       "   'postag[:2]': 'DT',\n",
       "   '-1:word.lower()': 'of',\n",
       "   '-1:word.istitle()': False,\n",
       "   '-1:word.isupper()': False,\n",
       "   '-1:postag': 'IN',\n",
       "   '-1:postag[:2]': 'IN',\n",
       "   '+1:word.lower()': 'plant',\n",
       "   '+1:word.istitle()': False,\n",
       "   '+1:word.isupper()': False,\n",
       "   '+1:postag': 'NN',\n",
       "   '+1:postag[:2]': 'NN'},\n",
       "  {'bias': 1.0,\n",
       "   'word.lower()': 'plant',\n",
       "   'word[-3:]': 'ant',\n",
       "   'word[-2:]': 'nt',\n",
       "   'word.isupper()': False,\n",
       "   'word.istitle()': False,\n",
       "   'word.isdigit()': False,\n",
       "   'postag': 'NN',\n",
       "   'postag[:2]': 'NN',\n",
       "   '-1:word.lower()': 'the',\n",
       "   '-1:word.istitle()': False,\n",
       "   '-1:word.isupper()': False,\n",
       "   '-1:postag': 'DT',\n",
       "   '-1:postag[:2]': 'DT',\n",
       "   '+1:word.lower()': 'wednesday',\n",
       "   '+1:word.istitle()': True,\n",
       "   '+1:word.isupper()': False,\n",
       "   '+1:postag': 'NNP',\n",
       "   '+1:postag[:2]': 'NN'},\n",
       "  {'bias': 1.0,\n",
       "   'word.lower()': 'wednesday',\n",
       "   'word[-3:]': 'day',\n",
       "   'word[-2:]': 'ay',\n",
       "   'word.isupper()': False,\n",
       "   'word.istitle()': True,\n",
       "   'word.isdigit()': False,\n",
       "   'postag': 'NNP',\n",
       "   'postag[:2]': 'NN',\n",
       "   '-1:word.lower()': 'plant',\n",
       "   '-1:word.istitle()': False,\n",
       "   '-1:word.isupper()': False,\n",
       "   '-1:postag': 'NN',\n",
       "   '-1:postag[:2]': 'NN',\n",
       "   '+1:word.lower()': ',',\n",
       "   '+1:word.istitle()': False,\n",
       "   '+1:word.isupper()': False,\n",
       "   '+1:postag': ',',\n",
       "   '+1:postag[:2]': ','},\n",
       "  {'bias': 1.0,\n",
       "   'word.lower()': ',',\n",
       "   'word[-3:]': ',',\n",
       "   'word[-2:]': ',',\n",
       "   'word.isupper()': False,\n",
       "   'word.istitle()': False,\n",
       "   'word.isdigit()': False,\n",
       "   'postag': ',',\n",
       "   'postag[:2]': ',',\n",
       "   '-1:word.lower()': 'wednesday',\n",
       "   '-1:word.istitle()': True,\n",
       "   '-1:word.isupper()': False,\n",
       "   '-1:postag': 'NNP',\n",
       "   '-1:postag[:2]': 'NN',\n",
       "   '+1:word.lower()': 'after',\n",
       "   '+1:word.istitle()': False,\n",
       "   '+1:word.isupper()': False,\n",
       "   '+1:postag': 'IN',\n",
       "   '+1:postag[:2]': 'IN'},\n",
       "  {'bias': 1.0,\n",
       "   'word.lower()': 'after',\n",
       "   'word[-3:]': 'ter',\n",
       "   'word[-2:]': 'er',\n",
       "   'word.isupper()': False,\n",
       "   'word.istitle()': False,\n",
       "   'word.isdigit()': False,\n",
       "   'postag': 'IN',\n",
       "   'postag[:2]': 'IN',\n",
       "   '-1:word.lower()': ',',\n",
       "   '-1:word.istitle()': False,\n",
       "   '-1:word.isupper()': False,\n",
       "   '-1:postag': ',',\n",
       "   '-1:postag[:2]': ',',\n",
       "   '+1:word.lower()': 'an',\n",
       "   '+1:word.istitle()': False,\n",
       "   '+1:word.isupper()': False,\n",
       "   '+1:postag': 'DT',\n",
       "   '+1:postag[:2]': 'DT'},\n",
       "  {'bias': 1.0,\n",
       "   'word.lower()': 'an',\n",
       "   'word[-3:]': 'an',\n",
       "   'word[-2:]': 'an',\n",
       "   'word.isupper()': False,\n",
       "   'word.istitle()': False,\n",
       "   'word.isdigit()': False,\n",
       "   'postag': 'DT',\n",
       "   'postag[:2]': 'DT',\n",
       "   '-1:word.lower()': 'after',\n",
       "   '-1:word.istitle()': False,\n",
       "   '-1:word.isupper()': False,\n",
       "   '-1:postag': 'IN',\n",
       "   '-1:postag[:2]': 'IN',\n",
       "   '+1:word.lower()': 'iaea',\n",
       "   '+1:word.istitle()': False,\n",
       "   '+1:word.isupper()': True,\n",
       "   '+1:postag': 'NNP',\n",
       "   '+1:postag[:2]': 'NN'},\n",
       "  {'bias': 1.0,\n",
       "   'word.lower()': 'iaea',\n",
       "   'word[-3:]': 'AEA',\n",
       "   'word[-2:]': 'EA',\n",
       "   'word.isupper()': True,\n",
       "   'word.istitle()': False,\n",
       "   'word.isdigit()': False,\n",
       "   'postag': 'NNP',\n",
       "   'postag[:2]': 'NN',\n",
       "   '-1:word.lower()': 'an',\n",
       "   '-1:word.istitle()': False,\n",
       "   '-1:word.isupper()': False,\n",
       "   '-1:postag': 'DT',\n",
       "   '-1:postag[:2]': 'DT',\n",
       "   '+1:word.lower()': 'surveillance',\n",
       "   '+1:word.istitle()': False,\n",
       "   '+1:word.isupper()': False,\n",
       "   '+1:postag': 'NN',\n",
       "   '+1:postag[:2]': 'NN'},\n",
       "  {'bias': 1.0,\n",
       "   'word.lower()': 'surveillance',\n",
       "   'word[-3:]': 'nce',\n",
       "   'word[-2:]': 'ce',\n",
       "   'word.isupper()': False,\n",
       "   'word.istitle()': False,\n",
       "   'word.isdigit()': False,\n",
       "   'postag': 'NN',\n",
       "   'postag[:2]': 'NN',\n",
       "   '-1:word.lower()': 'iaea',\n",
       "   '-1:word.istitle()': False,\n",
       "   '-1:word.isupper()': True,\n",
       "   '-1:postag': 'NNP',\n",
       "   '-1:postag[:2]': 'NN',\n",
       "   '+1:word.lower()': 'system',\n",
       "   '+1:word.istitle()': False,\n",
       "   '+1:word.isupper()': False,\n",
       "   '+1:postag': 'NN',\n",
       "   '+1:postag[:2]': 'NN'},\n",
       "  {'bias': 1.0,\n",
       "   'word.lower()': 'system',\n",
       "   'word[-3:]': 'tem',\n",
       "   'word[-2:]': 'em',\n",
       "   'word.isupper()': False,\n",
       "   'word.istitle()': False,\n",
       "   'word.isdigit()': False,\n",
       "   'postag': 'NN',\n",
       "   'postag[:2]': 'NN',\n",
       "   '-1:word.lower()': 'surveillance',\n",
       "   '-1:word.istitle()': False,\n",
       "   '-1:word.isupper()': False,\n",
       "   '-1:postag': 'NN',\n",
       "   '-1:postag[:2]': 'NN',\n",
       "   '+1:word.lower()': 'begins',\n",
       "   '+1:word.istitle()': False,\n",
       "   '+1:word.isupper()': False,\n",
       "   '+1:postag': 'VBZ',\n",
       "   '+1:postag[:2]': 'VB'},\n",
       "  {'bias': 1.0,\n",
       "   'word.lower()': 'begins',\n",
       "   'word[-3:]': 'ins',\n",
       "   'word[-2:]': 'ns',\n",
       "   'word.isupper()': False,\n",
       "   'word.istitle()': False,\n",
       "   'word.isdigit()': False,\n",
       "   'postag': 'VBZ',\n",
       "   'postag[:2]': 'VB',\n",
       "   '-1:word.lower()': 'system',\n",
       "   '-1:word.istitle()': False,\n",
       "   '-1:word.isupper()': False,\n",
       "   '-1:postag': 'NN',\n",
       "   '-1:postag[:2]': 'NN',\n",
       "   '+1:word.lower()': 'functioning',\n",
       "   '+1:word.istitle()': False,\n",
       "   '+1:word.isupper()': False,\n",
       "   '+1:postag': 'VBG',\n",
       "   '+1:postag[:2]': 'VB'},\n",
       "  {'bias': 1.0,\n",
       "   'word.lower()': 'functioning',\n",
       "   'word[-3:]': 'ing',\n",
       "   'word[-2:]': 'ng',\n",
       "   'word.isupper()': False,\n",
       "   'word.istitle()': False,\n",
       "   'word.isdigit()': False,\n",
       "   'postag': 'VBG',\n",
       "   'postag[:2]': 'VB',\n",
       "   '-1:word.lower()': 'begins',\n",
       "   '-1:word.istitle()': False,\n",
       "   '-1:word.isupper()': False,\n",
       "   '-1:postag': 'VBZ',\n",
       "   '-1:postag[:2]': 'VB',\n",
       "   '+1:word.lower()': '.',\n",
       "   '+1:word.istitle()': False,\n",
       "   '+1:word.isupper()': False,\n",
       "   '+1:postag': '.',\n",
       "   '+1:postag[:2]': '.'},\n",
       "  {'bias': 1.0,\n",
       "   'word.lower()': '.',\n",
       "   'word[-3:]': '.',\n",
       "   'word[-2:]': '.',\n",
       "   'word.isupper()': False,\n",
       "   'word.istitle()': False,\n",
       "   'word.isdigit()': False,\n",
       "   'postag': '.',\n",
       "   'postag[:2]': '.',\n",
       "   '-1:word.lower()': 'functioning',\n",
       "   '-1:word.istitle()': False,\n",
       "   '-1:word.isupper()': False,\n",
       "   '-1:postag': 'VBG',\n",
       "   '-1:postag[:2]': 'VB',\n",
       "   'EOS': True}]]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CRF(algorithm='lbfgs', all_possible_states=None,\n",
       "  all_possible_transitions=False, averaging=None, c=None, c1=0.1, c2=0.1,\n",
       "  calibration_candidates=None, calibration_eta=None,\n",
       "  calibration_max_trials=None, calibration_rate=None,\n",
       "  calibration_samples=None, delta=None, epsilon=None, error_sensitive=None,\n",
       "  gamma=None, keep_tempfiles=None, linesearch=None, max_iterations=100,\n",
       "  max_linesearch=None, min_freq=None, model_filename=None,\n",
       "  num_memories=None, pa_type=None, period=None, trainer_cls=None,\n",
       "  variance=None, verbose=False)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "crf.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import eli5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
